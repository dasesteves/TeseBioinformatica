\chapter{Methodology}
\label{chap:Methodology}

This chapter details the methodological framework that guided this research. It begins by outlining the high-level research paradigm and strategy, then elaborates on the specific design of the study, the development methodology employed, and the methods used for data collection and evaluation. The chapter concludes with a discussion of ethical considerations and the inherent limitations of the study.

\section{Research Paradigm and Strategy}

This research adopts a \textit{pragmatic paradigm}, integrating quantitative and qualitative methods to address the complex, real-world challenges of hospital medication management \cite{venkatesh2003}. The work is fundamentally grounded in \textit{Design Science Research (\gls{dsr})}, an approach that emphasizes the creation and evaluation of an innovative artifact—in this case, an integrated software system—to solve a concrete organizational problem \cite{martin2017}. This paradigm is ideal as it provides a rigorous structure for developing a technologically sound solution while ensuring its practical relevance and utility within the specific context of the \gls{scmvv} hospital.

To operationalize the DSR paradigm, an \textit{Action Research} strategy is employed \cite{greenhalgh2017}. This choice is dictated by the dynamic nature of the clinical environment, which requires an iterative and adaptive approach. Action Research involves continuous cycles of planning, acting, observing, and reflecting, allowing for the incremental improvement of the system based on empirical feedback gathered directly from healthcare professionals. By making practitioners active partners in the research, this strategy fosters a co-creation of knowledge and ensures the final artifact is deeply aligned with user needs and clinical workflows.

\section{Research Design and Execution}

The project is structured to answer core research questions concerning the impact and implementation of integrated clinical systems. Guiding questions include: 1) How can an integrated system reduce medication errors? 2) What are critical success factors for adoption in a hospital setting? 3) How can its impact be evaluated rigorously?

To address these questions, the work follows a series of structured phases aligned with the work plan (Chapter~\ref{chap:WorkPlan}). The initial \textit{Analysis and Planning} phase focuses on requirement elicitation and a deep analysis of the legacy \gls{aida}-PCE system and current clinical workflows. This analysis is informed by stakeholder input (e.g., interviews and observation) and by reviewing existing processes and data extracts where available, producing process maps and an initial architectural blueprint (see Sections~\ref{sec:context_scmvv} and~\ref{sec:as_is_architecture}).

\subsection{Development and Implementation Methodology}

An adapted \textit{agile methodology} is adopted, combining user-centered design and iterative prototyping to enable continuous engagement with clinicians \cite{fowler2018}. Implementation progresses in focused modules: (i) core infrastructure (security, \gls{jwt}-based authentication, data access), (ii) clinical modules (user/treatment registration, pharmaceutical validation), and (iii) integration with legacy components, namely the \gls{aida}-PCE (Oracle) where applicable. When decision support (\gls{cdss}) features are introduced, they are scoped and validated iteratively with domain stakeholders.

Integration activities emphasize careful mapping of data schemas and safe interoperability with existing systems. The approach privileges incremental integration with legacy assets over big-bang replacement, in line with the overall modernization strategy and the as-is constraints documented in Sections~\ref{sec:context_scmvv} and~\ref{sec:current_process_org}.

Quality assurance activities include functional, integration and performance testing, as well as formative usability assessments with representative users. Performance targets and acceptance criteria are aligned with Chapter~\ref{chap:ExpectedResults} and are verified in controlled test environments prior to any pilot.

\subsection{Research Hypotheses}
The evaluation follows explicit hypotheses to guide measurement and interpretation:
\begin{itemize}
    \item H1: An integrated medication-management system reduces medication errors relative to a documented baseline.
    \item H2: End-to-end process cycle times (prescription to administration) are reduced relative to baseline timings.
    \item H3: User acceptance achieves a "Good" or better outcome on SUS, corroborated by qualitative feedback.
    \item H4: Data coherence across systems improves (fewer redundancies/discrepancies in key fields).
\end{itemize}

\subsection{Risk Management Strategy}

A proactive risk management strategy is integral to the methodology. As detailed in the Risk Analysis of the Work Plan (Section~\ref{sec:RiskAnalysis}), key risks include resistance to change, technical incompatibilities with legacy systems, and potential performance degradation. Mitigation strategies include structured change management (training, stakeholder champions), incremental integration with thorough testing in staging environments, and resilience mechanisms for critical functionalities.

\subsection{Change Management and Training Plan}
A structured change management and training plan accompanies implementation, centered on: (i) early involvement of clinical champions, (ii) short, role-tailored training bursts with practical scenarios, (iii) feedback cycles embedded in sprints, and (iv) quick-reference materials integrated in the UI. Placeholders for training artifacts and schedules are provided in Appendix~\ref{app:details_results} and linked from Results when available.

\section{Data Collection and Evaluation}

To evaluate system impact, a mixed-methods approach to data collection is used, gathering both quantitative and qualitative data during the pilot or evaluation period.

\subsection{Quantitative Data Collection}
Quantitative data focuses on objective, measurable indicators of performance and safety. System performance metrics (e.g., response time, uptime) are monitored. Clinical process data (e.g., medication error rates, task completion times) are compared against baseline data from the legacy system where available. Usage metrics (e.g., active users, feature adoption) are tracked to gauge engagement.

\subsection{Qualitative Data Collection}
Qualitative data provides contextual insights into user experience. In-depth, semi-structured interviews with healthcare professionals and managers are used to understand perceived impact on work. Direct observation of clinical workflows before and after system introduction informs how the system integrates into practice and any unintended consequences or workarounds.

\subsection{Evaluation Criteria}
Success criteria are rooted in the Donabedian model for quality of care (structure, process, outcomes). The specific Key Performance Indicators (KPIs) derived from these criteria are detailed in Chapter~\ref{chap:ExpectedResults} (Section~\ref{sec:KPIs}).

For \textit{Patient Safety}, the primary criterion is a statistically supported reduction in medication errors. For \textit{Operational Efficiency}, success is defined by measurable reductions in process cycle times and improvements in interdisciplinary communication. For \textit{User Acceptance}, evaluation relies on the System Usability Scale (SUS) complemented by qualitative feedback and adoption indicators.

\subsection{Statistical Analysis Plan (overview)}
The analysis follows established methods suitable to the data at hand (details in Appendix~\ref{app:details_results}).
\begin{itemize}
    \item Error rates (proportions): pre-post comparison using appropriate tests for proportions (e.g., chi-square or Fisher's exact), with confidence intervals for absolute/relative differences; sensitivity checks for definition changes.
    \item Timing metrics (continuous): comparison of cycle-time components using parametric (t-test) or non-parametric (Mann–Whitney/Wilcoxon) tests as appropriate after distribution checks; report medians/IQR and means/SD.
    \item Repeated measures/series: where applicable, segmented time-series or control charts to assess trends over the pilot; robustness checks for autocorrelation.
    \item Multiple comparisons and effect sizes: adjust for multiplicity where necessary; report effect sizes (risk difference/ratio; Cohen's d or non-parametric alternatives).
    \item Qualitative synthesis: thematic analysis of interview/focus-group data triangulated with quantitative findings (no statistics applied here).
\end{itemize}

\section{Ethical Considerations and Limitations}

\subsection{Ethical Protocol}
Prior to any data collection or pilot, appropriate ethical approval is obtained from the competent Ethics Committee, and all research activities adhere strictly to the General Data Protection Regulation (GDPR) \cite{european2016}. Patient data is anonymized before analysis, informed consent is sought from participating professionals, and technical/procedural safeguards are implemented to protect confidentiality and integrity.

\subsection{Security, Privacy and Compliance Considerations}
Security and privacy safeguards accompany all stages of the project. Controls include role-based access, authentication and authorization, encrypted communications, immutable audit trails for medication-related actions, and least-privilege principles. Compliance follows applicable legal and institutional requirements (e.g., GDPR), and alignment with national guidance (e.g., SNS/SPMS) is pursued where relevant, as summarized in Section~\ref{sec:national_context_portugal}.

\subsection{Limitations of the Study}
The findings must be interpreted in light of methodological and technical limitations. The single-site case study design may limit generalizability to other hospital contexts. A time-bounded evaluation period may not capture long-term effects on organizational culture or patient outcomes. A pre-post comparison without a parallel control group cannot exclude confounding influences. Finally, reliance on legacy data sources (e.g., Oracle-based \gls{aida}) and the evolving adoption of interoperability standards may impose constraints and suggest directions for future work.


